{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions for Working with Train DNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file to call functions from for working with the TrainDNA dataset. This keeps all of the files consistent across the notebooks, and allows them to be updated easily. **DO NOT CHANGE THEM WITHOUT THOUGHT PLEASE!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuro_python.neuro_compute import spark_manager as spm\n",
    "import neuro_python.neuro_compute.notebook_manager as notebook_manager\n",
    "from neuro_python.neuro_data import schema_manager as sm\n",
    "from neuro_python.neuro_data import sql_query as sq\n",
    "from neuro_python.neuro_data import sql_commands as sc\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as pgo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ContextId': 'ab2bf544-b175-44bb-940e-7d02c877b6fb',\n",
       " 'IdleContextLifeInMinutes': 20}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.create_context('TrainDNAFunctionsHB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function finds the number of true starts for a dataset, by filtering out the non-CPG Startup Signals, and then classifying correct starts as when there is more than 30 min between start events. If the events occur closer than that, then the Train is assumed to have not started correctly i.e. startTimes = [10:00, 10:01, 18:00] then successful start times = [10:01, 18:00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dcec5fd3b454889bea71b6ae7564f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Label(value='CommandId: 19702d50-c75a-441e-8eb1-1653534ad609'), FloatProgress(value=0.0, max=1.0), Button(description='Cancel', style=ButtonStyle())))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark \n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import pandas_udf,PandasUDFType\n",
    "\n",
    "schema2 = StructType([\n",
    "    StructField(\"CSN\", StringType()),\n",
    "    StructField(\"EventID\", LongType()),\n",
    "    StructField(\"DateTime\", StringType())\n",
    "])\n",
    "\n",
    " \n",
    "\n",
    "@pandas_udf(schema2, functionType=PandasUDFType.GROUPED_MAP)\n",
    "def startTimes(df):\n",
    "    gr = df['CSN'].iloc[0]#used for the default returned dataframe if no data being returned\n",
    "    EventID = 65533\n",
    "    events = df[df['EventID']==EventID].sort_values(['DateTime']) #start events\n",
    "    DateTime = pd.to_numeric(pd.to_datetime(events['DateTime']))/1e9 #convert ns to s\n",
    "    DateTimeNext = DateTime.shift(periods=-1) # -1 because we want to find the gap until the NEXT one (ie. if THIS event failed)\n",
    "    time_diff = (DateTimeNext-DateTime) #Find the difference in event times\n",
    "    df_less15m = events[((time_diff>(30*60)) | (time_diff.isnull()))]#more than 30 min or when time_diff is null, as that is the last recorded event\n",
    "    default_df = pd.DataFrame([[gr,EventID,'None']]) #Returned if no start events detected - filter out using Datetime == none\n",
    "    if len(df_less15m.index)>0:\n",
    "        return_df = pd.DataFrame(df_less15m[['CSN','EventID','DateTime']])\n",
    "        #reset column names, this needs to be done otherwise it won't match the schema above. It works when we do .mean() etc\n",
    "        #because that doesn't give a named column when we create the dataframe, whereas this does.\n",
    "        return_df = return_df.T.reset_index(drop=True).T #this feels hacky\n",
    "        return return_df\n",
    "    else:\n",
    "        return default_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fail Starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one finds the starts which are closer than 30 minutes but further than 10 seconds apart. This means that it is not a repeat signal recorded or the operator pressing the button multiple times, and not a successful start. I.e. start times = [10:00:00, 10:00:03, 10:01:00, 12:00:30] returns 10:00:03 as a failed event\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2bb74453e6433c826ef777c11dfbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Label(value='CommandId: 16e57475-092f-4ff3-9f2a-83da8b290fc7'), FloatProgress(value=0.0, max=1.0), Button(description='Cancel', style=ButtonStyle())))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark \n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import pandas_udf,PandasUDFType\n",
    "\n",
    "schema3 = StructType([\n",
    "    StructField(\"CSN\", StringType()),\n",
    "    StructField(\"EventID\", IntegerType()),\n",
    "    StructField(\"DateTime\", StringType())\n",
    "])\n",
    "\n",
    "@pandas_udf(schema3, functionType=PandasUDFType.GROUPED_MAP)\n",
    "def failTimes(df):\n",
    "    gr = df['CSN'].iloc[0]#used for the default returned dataframe if no data being returned\n",
    "    EventID = 65533\n",
    "    events = df[df['EventID']==EventID].sort_values(['DateTime'])\n",
    "    DateTime = pd.to_numeric(pd.to_datetime(events['DateTime']))/1e9 #convert ns to s\n",
    "    DateTimeNext = DateTime.shift(periods=-1) # -1 because we want to find the gap until the NEXT one (ie. if THIS event failed)\n",
    "    time_diff = (DateTimeNext-DateTime)\n",
    "    df_less15m = events[((time_diff<(30*60)) & (time_diff > 10))]#more than 10s, less than 30 mins\n",
    "    default_df = pd.DataFrame([[gr,EventID,'None']])\n",
    "    if len(df_less15m.index)>0:\n",
    "        return_df = pd.DataFrame(df_less15m[['CSN','EventID','DateTime']])\n",
    "        #reset column names, this needs to be done otherwise it won't match the schema above. It works when we do .mean() etc\n",
    "        #because that doesn't give a named column when we create the dataframe, whereas this does.\n",
    "        return_df = return_df.T.reset_index(drop=True).T #this feels hacky\n",
    "        return return_df\n",
    "    else:\n",
    "        return default_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicate signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This UDF removes sigals which have the same CSN and Event ID which occur within 1 second of each other, as it assumes that are a duplicate alert i.e. signals for one CSN of the same Event ID occured at [10:00:00:123, 10:00:00:956, 10:00:01:342] returns [10:00:00, 10:00:01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2770c2afa9b54a7382d3085d9cd4de34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Label(value='CommandId: f10cd0d8-3550-4b16-a849-dd153e529f01'), FloatProgress(value=0.0, max=1.0), Button(description='Cancel', style=ButtonStyle())))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark \n",
    "#Run udf on octSelectEvents to remove signals with same second values\n",
    "#i.e same eventID time =10:00:01 and again with time = 10:00:01 then remove one\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import pandas_udf,PandasUDFType\n",
    "\n",
    "schema5 = StructType([\n",
    "    StructField(\"CSN\", StringType()),\n",
    "    StructField(\"EventID\", IntegerType()),\n",
    "    StructField(\"EventIDNext\", IntegerType()),\n",
    "    StructField(\"DateTime\", StringType()),\n",
    "    StructField(\"DateTimeInt\", IntegerType()),\n",
    "    StructField(\"DateTimeIntNext\", IntegerType()),\n",
    "    StructField(\"timeDiff\", IntegerType())\n",
    "])\n",
    "\n",
    "@pandas_udf(schema5, functionType=PandasUDFType.GROUPED_MAP)\n",
    "def removeDuplicates(df):\n",
    "    df.rename(columns=lambda x: x.lstrip(), inplace = True)\n",
    "    \n",
    "    gr = df['CSN'].iloc[0]#used for the default returned dataframe if no data being returned\n",
    "    EventID = 65533\n",
    "    df['DateTimeInt'] = pd.to_numeric(pd.to_datetime(df['DateTime']))/1e9 #convert ns to s\n",
    "    df = df.sort_values(['EventID','DateTimeInt'])\n",
    "\n",
    "    df['DateTimeIntNext'] = df['DateTimeInt'].shift(periods=-1) # -1 because we want to find the gap until the NEXT one (ie. if THIS event failed)\n",
    "    df['EventIDNext'] = df['EventID'].shift(periods=-1)\n",
    "    \n",
    "    df['timeDiff'] = (df['DateTimeIntNext']-df['DateTimeInt'])\n",
    "    \n",
    "   #Remove the rows with timeDiff between -1 and 1 and the same event ID\n",
    "    dResult = df[((df.timeDiff < -1) | (df.timeDiff > 1)) | (df.EventID != df.EventIDNext)]\n",
    "    \n",
    "    #If empty array: i.e. only one event type happens, all at the same time, return the first row\n",
    "    if dResult.empty:\n",
    "        dResult = df.iloc[[0]]\n",
    "    return dResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get time relative to the closest event of a chosen event type - i.e. Start up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This UDF returns the time between each event of any ID and the nearest event of a chosen event ID, with positive or negative seconds indicating after or before the event occuring. This can be used to analyse Train behaviour around a given event, for example the start up, or shut down of a train. Filtering using removeDuplicates or successStarts is reccomended to remove some of the events that wish to be analysed. The event to analyse is declared in startID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3eda6a746a24108b705c9fdded3e792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(Output(), HBox(children=(Label(value='CommandId: 2566b8dd-c819-4ca8-8b22-8dcfcbbff444'), FloatProgress(value=0.0, max=1.0), Button(description='Cancel', style=ButtonStyle())))))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import pandas_udf,PandasUDFType\n",
    "\n",
    "schema4 = StructType([\n",
    "    StructField(\"CSN\", StringType()),\n",
    "    StructField(\"EventID\", IntegerType()),\n",
    "    StructField(\"DateTime\", StringType()), \n",
    "    StructField(\"TimeToStart\", IntegerType()),\n",
    "    StructField(\"DateTimeInt\", IntegerType()),\n",
    "    StructField(\"startIndex\", IntegerType())\n",
    "])\n",
    "\n",
    "@pandas_udf(schema4, functionType=PandasUDFType.GROUPED_MAP)\n",
    "def getClosestStartsandTimes(df):\n",
    "    df.rename(columns=lambda x: x.lstrip(), inplace = True)\n",
    "    gr = df['CSN'].iloc[0]#used for the default returned dataframe if no data being returned\n",
    "    \n",
    "    #Get time in seconds\n",
    "    df['DateTimeInt'] = pd.to_numeric(pd.to_datetime(df['DateTime']))/1e9 #convert ns to s\n",
    "    \n",
    "    #Get Start Event times - startID can be changed for any event to anaylse train behaviour around that event\n",
    "    startID = 65533\n",
    "    startEvents = df[df['EventID']==startID]\n",
    "    \n",
    "    #if no start events for CSN, return empty array, otherwise perfrom calcs - reccommend that a check is performed after the calling of this function to check if any Datetime is listed as 'WRONG:\n",
    "    if startEvents.empty:\n",
    "        otherEvents = pd.DataFrame([[gr,65533,'WRONG',1,2,3]])\n",
    "    else:#Otherwise...\n",
    "        otherEvents = df[df['EventID']!=startID] #Remove the start events\n",
    "        st = startEvents['DateTimeInt'].values #outputs a list\n",
    "        ot = otherEvents['DateTimeInt'].values\n",
    "        \n",
    "        #put into a numpy array to make use of numpy functions\n",
    "        stNp = np.array(st) #stNp is a list of the times of the start events for the time period - compare time of each event to these vals\n",
    "        otNp = np.array(ot)\n",
    "        \n",
    "        #Get shape of df to find no of rows\n",
    "        col = len(ot)\n",
    "        ot = ot.reshape(col,1)\n",
    "\n",
    "        #Add start times to each row of dataframe\n",
    "        stList = stNp #Declaring the list to be appending stNp to\n",
    "        for i in range(col-1):\n",
    "            stList = np.vstack((stList,stNp))\n",
    "        \n",
    "        #compute the time diff for each start time\n",
    "        timeDiff = ot - stList\n",
    "        \n",
    "        #Find the minimum time value, and the index which it occurs at\n",
    "        x = np.argmin(abs(timeDiff),axis=1).reshape(col,1)\n",
    "        otherEvents['startIndex'] = x\n",
    "        \n",
    "        #Store the minimum time in the correct rows\n",
    "        timeDiffResult = []\n",
    "        for i in range(col):\n",
    "            val = (timeDiff[i,x[i]])\n",
    "            timeDiffResult.append(val[0])\n",
    "\n",
    "        #Make new numpy of timeDiffResult and get min - NOT USED ANY MORE\n",
    "        minTime = np.argmin(abs(np.array(timeDiffResult)))\n",
    "\n",
    "        #Make new col with the time ebtween said event and the nearest start Time\n",
    "        otherEvents['TimeToStart'] = (timeDiffResult)\n",
    "\n",
    "\n",
    "    return otherEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
